{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 30.01.2025\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 16.02.2025\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 23.02.2025\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "Использование генеративных языковых моделей разрешено только в случае явного указания на это. Необходимо прописать (в соответствующих пунктах, где использовались, либо в начале/конце работы):\n",
    "- какая языковая модель использовалась\n",
    "- какие использовались промпты и в каких частях работы\n",
    "- с какими сложностями вы столкнулись при использовании генеративных моделей, с чем они помогли больше всего\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1 Способ \n",
    "#import keras\n",
    "#from keras.datasets import fashion_mnist\n",
    "#(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 2 Способ (если первый не работает)\n",
    "from sklearn.datasets import fetch_openml\n",
    "def load_fashion_mnist():\n",
    "     X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n",
    "     X = X.reshape(-1, 28, 28).astype('uint8')\n",
    "     y = y.astype('int64')\n",
    "     x_train, x_test = X[:60000], X[60000:]\n",
    "     y_train, y_test = y[:60000], y[60000:]\n",
    "     return (x_train, y_train), (x_test, y_test)\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = load_fashion_mnist()\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 0. (0.25 баллов)__\n",
    "\n",
    "**Вопрос:** зачем в алгоритме нужен метод главных компонент? \n",
    "\n",
    "**Ответ:** PCA здесь используется для понижения размерности выборки, сохраняя наиболее важную информацию о данных (за счеь того, что сохраняются главные компоненты). Во-первых, уменьшаются вычислительные затраты, так как используется меньше признаков. Во-вторых, снижается вероятность переобучения, потому что модель строится на более информативных признаках, и мы выкидываем шум и неполезные признаки. В-третьих, оптимизируется ядро RFF, так как низкоразмерное пространство позволяет более эффективно аппроксимировать ядро"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (3 балла)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса в `homework_practice_08_rff.py` (допишите его и исправьте несостыковки в классе пайплайна) или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jP8yepx8K-hT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8581\n"
     ]
    }
   ],
   "source": [
    "from homework_practice_08_rff import RFFPipeline, RandomFeatureCreator\n",
    "\n",
    "pipeline = RFFPipeline(n_features=1000, new_dim=50, feature_creator_class=RandomFeatureCreator)\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "accuracy = pipeline.score(x_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (2.5 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучите градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost. \n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM: \n",
      " accuracy: 0.8378 \n",
      " time: 1482.0719 sec\n"
     ]
    }
   ],
   "source": [
    "svm_linear = LinearSVC(dual=False)\n",
    "start_time = time.time()\n",
    "svm_linear.fit(x_train, y_train)\n",
    "end_time = time.time() \n",
    "\n",
    "y_pred = svm_linear.predict(x_test)\n",
    "svm_linear_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Linear SVM: \\n accuracy: {svm_linear_accuracy:.4f} \\n time: {end_time-start_time:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM: \n",
      " accuracy: 0.8639 \n",
      " time: 27.6115 sec\n"
     ]
    }
   ],
   "source": [
    "svm_kernel = SVC(kernel='rbf')\n",
    "start_time = time.time()\n",
    "svm_kernel.fit(x_train[:20000], y_train[:20000])\n",
    "end_time = time.time() \n",
    "\n",
    "y_pred = svm_kernel.predict(x_test)\n",
    "svm_kernel_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Kernel SVM: \\n accuracy: {svm_kernel_accuracy:.4f} \\n time: {end_time-start_time:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random + Linear SVM: \n",
      " accuracy: 0.8628 \n",
      " time: 122.7993 sec\n"
     ]
    }
   ],
   "source": [
    "from homework_practice_08_rff import RFFPipeline, RandomFeatureCreator\n",
    "\n",
    "\n",
    "rff_pipeline = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, classifier_class=LinearSVC ,feature_creator_class=RandomFeatureCreator)\n",
    "start_time = time.time()\n",
    "rff_pipeline.fit(x_train, y_train)\n",
    "end_time = time.time() \n",
    "\n",
    "y_pred = rff_pipeline.predict(x_test)\n",
    "rff_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Random + Linear SVM: \\n accuracy: {rff_accuracy:.4f} \\n time: {end_time-start_time:.4f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*извиняюсь, но на новом ноуте не получается установить catboost или lightgbm, так что сделала так*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting + PCA: \n",
      " accuracy: 0.8351 \n",
      " time: 843.1239 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "X_train_pca = pca.fit_transform(x_train)\n",
    "X_test_pca = pca.transform(x_test)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, verbose=0)\n",
    "start_time = time.time()\n",
    "gb_model.fit(X_train_pca, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred = gb_model.predict(X_test_pca)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Gradient Boosting + PCA: \\n accuracy: {gb_accuracy:.4f} \\n time: {end_time-start_time:.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Logreg (for use_PCA=True and use_PCA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with PCA: accuracy = 0.8581\n"
     ]
    }
   ],
   "source": [
    "rff_pipeline_pca = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, feature_creator_class=RandomFeatureCreator)\n",
    "rff_pipeline_pca.fit(x_train, y_train)\n",
    "y_pred_pca = rff_pipeline_pca.predict(x_test)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f\"with PCA: accuracy = {accuracy_pca:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without PCA: accuracy = 0.8606\n"
     ]
    }
   ],
   "source": [
    "rff_pipeline_no_pca = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, feature_creator_class=RandomFeatureCreator)\n",
    "rff_pipeline_no_pca.fit(x_train, y_train)\n",
    "y_pred_no_pca = rff_pipeline_no_pca.predict(x_test)\n",
    "accuracy_no_pca = accuracy_score(y_test, y_pred_no_pca)\n",
    "print(f\"without PCA: accuracy = {accuracy_no_pca:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Linear SVM (for use_PCA=True and use_PCA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with PCA: accuracy = 0.8768\n"
     ]
    }
   ],
   "source": [
    "rff_pipeline_svm = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier_class=LinearSVC,feature_creator_class=RandomFeatureCreator)\n",
    "rff_pipeline_svm.fit(x_train, y_train)\n",
    "y_pred_svm = rff_pipeline_svm.predict(x_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"with PCA: accuracy = {accuracy_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without PCA: accuracy = 0.8635\n"
     ]
    }
   ],
   "source": [
    "rff_pipeline_svm = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, classifier_class=LinearSVC, feature_creator_class=RandomFeatureCreator)\n",
    "rff_pipeline_svm.fit(x_train, y_train)\n",
    "y_pred_svm = rff_pipeline_svm.predict(x_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"without PCA: accuracy = {accuracy_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с линейным SVM получается немного выше точность, чем с логистической регрессией, но не значительно\n",
    "\n",
    "предварительное понижение размерности при помощи PCA дает некоторое ухудшение по точности, но не значительное (для логрега), для линейного SVM - незначительное улучшение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features = 10: accuracy = 0.6105\n",
      "n_features = 25: accuracy = 0.7471\n",
      "n_features = 50: accuracy = 0.8032\n",
      "n_features = 100: accuracy = 0.8359\n",
      "n_features = 200: accuracy = 0.8465\n",
      "n_features = 350: accuracy = 0.8525\n",
      "n_features = 500: accuracy = 0.8548\n",
      "n_features = 1000: accuracy = 0.8609\n",
      "n_features = 2000: accuracy = 0.8586\n"
     ]
    }
   ],
   "source": [
    "n_features_val = [10, 25, 50, 100, 200, 350, 500, 1000, 2000]\n",
    "accuracies = []\n",
    "\n",
    "for n in n_features_val:\n",
    "    rff_pipeline = RFFPipeline(n_features=n, new_dim=50, use_PCA=True, feature_creator_class=RandomFeatureCreator)\n",
    "    rff_pipeline.fit(x_train, y_train)\n",
    "    y_pred = rff_pipeline.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    print(f\"n_features = {n}: accuracy = {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(n_features_val, accuracies)\n",
    "plt.xlabel('n_features')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('dependence of accuracy on n_features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "действительно выходит на плато при росте n_features: как можно заметить при n_features=500 и выше точность практически не меняется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 1.5 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет), n_features=new_dim и n_features < new_dim также должны работать, убедитесь в этом. Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rff_pipeline = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, feature_creator_class=RandomFeatureCreator)\\nrff_pipeline.fit(x_train, y_train)\\ny_pred = rff_pipeline.predict(x_test)\\nacc = accuracy_score(y_test, y_pred)\\nprint(f\"accuracy rff= {acc:.4f}\")'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rff_pipeline = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, feature_creator_class=RandomFeatureCreator)\n",
    "rff_pipeline.fit(x_train, y_train)\n",
    "y_pred = rff_pipeline.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"accuracy rff= {acc:.4f}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from homework_practice_08_rff import OrthogonalRandomFeatureCreator\\n\\norff_pipeline = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, feature_creator_class=OrthogonalRandomFeatureCreator)\\norff_pipeline.fit(x_train, y_train)\\ny_pred = orff_pipeline.predict(x_test)\\nacc = accuracy_score(y_test, y_pred)\\nprint(f\"accuracy orff= {acc:.4f}\")'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from homework_practice_08_rff import OrthogonalRandomFeatureCreator\n",
    "\n",
    "orff_pipeline = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, feature_creator_class=OrthogonalRandomFeatureCreator)\n",
    "orff_pipeline.fit(x_train, y_train)\n",
    "y_pred = orff_pipeline.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"accuracy orff= {acc:.4f}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 1 балл)__\n",
    "\n",
    "Существует большое количество работ, где идея RFF развивается, предлагаются её обобщения (которые, по сути, выливаются в другие преобразования признаков, не обязательно уже тригонометрические). Возьмите любую из таких работ, кратко опишите идею, имплементируйте её и сравните качество с ORF и RFF, которые вы запрограммировали выше.\n",
    "\n",
    "Ссылки на статьи, где обсуждаются вариации RFF для разных ядер, можно найти в окрестности таблицы 1 в работе https://arxiv.org/pdf/1407.5599  \n",
    "\n",
    "___ссылка на работу:___\n",
    "\n",
    "___описание идеи:___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "# Пример "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6. (Максимум 2.5 балла)__\n",
    "\n",
    "Реализуйте класс ядровой Ridge регрессии (Лекция 13, $\\S 1.2$), для оптимизации используте градиентный спуск **[1 балл максимум]**, также добавьте возможность использовать аналитическую формулу **[1 балл максимум]**. Для градиентного спуска выпишите градиент ниже **[0.5 баллов максимум]**. \n",
    "Подумайте о том, как в формулах правильно учесть свободный коэффициент. \n",
    "\n",
    "Затем адаптируйте вашу реализацию RFF под задачу регрессии. Сравните вашу ядровую регрессию и RFF на синтетических данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь: \n",
    "$$\n",
    "Q(w) = \\frac{1}{2} ||\\Phi \\Phi^T w - y||^2 + \\frac{\\lambda}{2} w^T \\Phi \\Phi^T w \\rightarrow \\min_w,\n",
    "$$\n",
    "где $\\Phi \\Phi^T = K$, $K = (k(x_i, x_j))_{i, j = 1}^{\\ell}$.\n",
    "\n",
    "Предсказание: \n",
    "$\n",
    "y(x) = k(x)^T w,\n",
    "$\n",
    "где $k(x)$ — вектор функций ядра от пар объектов $(x, x_i)_{i=1}^{\\ell}$.\n",
    "\n",
    "___Выведите градиент:___ \n",
    "\n",
    "\n",
    "1. \n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{1}{2} ||\\Phi \\Phi^T w - y||^2 = \\frac{1}{2} (\\Phi \\Phi^T w - y)^T (\\Phi \\Phi^T w - y)\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n",
    "\\nabla_w \\left( \\frac{1}{2} (\\Phi \\Phi^T w - y)^T (\\Phi \\Phi^T w - y) \\right) = \\Phi \\Phi^T (\\Phi \\Phi^T w - y)\n",
    "\n",
    "$$\n",
    "\n",
    "2.\n",
    "$$\n",
    "\n",
    "\\frac{\\lambda}{2} w^T \\Phi \\Phi^T w = \\frac{\\lambda}{2} w^T K w\n",
    "\n",
    "$$\n",
    "$$\n",
    "\n",
    "\\nabla_w \\left( \\frac{\\lambda}{2} w^T K w \\right) = \\lambda K w\n",
    "\n",
    "$$\n",
    "\n",
    "Итого получаем:\n",
    "\n",
    "$$\n",
    "\n",
    "\\nabla_w Q(w) = \\Phi \\Phi^T (\\Phi \\Phi^T w - y) + \\lambda K w = K (\\Phi \\Phi^T w - y) + \\lambda K w\n",
    "\n",
    "$$\n",
    "\n",
    "\n",
    "Вы можете изменять представленный шаблон в файле `homework_practice_08_kernel_regression.py` по своему усмотрению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "я решила написать тут, а не писать в шаблоне, надеюсь это ок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression:\n",
    "    def __init__(self, kernel='rbf', lambda_reg=1.0, use_analytic=False, max_iter=1000, \n",
    "                 learning_rate=0.01, gamma=1.0, tol=1e-6):\n",
    "        self.kernel_type = kernel\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.use_analytic = use_analytic\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.tol = tol  \n",
    "        self.alpha = None\n",
    "        self.X_train = None\n",
    "        self.bias = 0\n",
    "\n",
    "    def compute_kernel(self, X1, X2):\n",
    "        if self.kernel_type == 'rbf':\n",
    "            n_samples1, n_samples2 = X1.shape[0], X2.shape[0]\n",
    "            distances = []\n",
    "            n_pairs = min(10000, n_samples1 * n_samples2)\n",
    "        \n",
    "            while len(distances) < n_pairs:\n",
    "                idx1 = np.random.randint(0, n_samples1)\n",
    "                idx2 = np.random.randint(0, n_samples2)\n",
    "            \n",
    "                if idx1 != idx2:\n",
    "                    dist = np.sum((X1[idx1] - X2[idx2]) ** 2)\n",
    "                    distances.append(dist)\n",
    "        \n",
    "            sigma_squared = np.median(np.array(distances))\n",
    "            gamma = 1 / (2 * sigma_squared + 1e-8)  \n",
    "            K = np.zeros((n_samples1, n_samples2))\n",
    "            for i in range(n_samples1):\n",
    "                for j in range(n_samples2):\n",
    "                    sq_dist = np.sum((X1[i] - X2[j]) ** 2)\n",
    "                    K[i, j] = np.exp(-gamma * sq_dist)\n",
    "        \n",
    "            return K\n",
    "        elif self.kernel_type == 'linear':\n",
    "            return np.dot(X1, X2.T)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        y_centered = y - np.mean(y)\n",
    "        self.bias = np.mean(y)\n",
    "\n",
    "        K = self.compute_kernel(X, X)\n",
    "        \n",
    "        if self.use_analytic:\n",
    "            self.alpha = np.linalg.solve(K + self.lambda_reg * np.eye(n_samples), y_centered)\n",
    "        else:\n",
    "            self.alpha = np.zeros(n_samples)\n",
    "            prev_loss = float('inf')\n",
    "            \n",
    "            for i in range(self.max_iter):\n",
    "                pred = K.dot(self.alpha)\n",
    "                grad = K.dot(pred - y_centered) + self.lambda_reg * K.dot(self.alpha)\n",
    "                grad_norm = np.linalg.norm(grad)\n",
    "                if grad_norm > 1:\n",
    "                    grad = grad / grad_norm\n",
    "        \n",
    "                self.alpha -= self.learning_rate * grad\n",
    "                \n",
    "                current_loss = 0.5 * np.sum((pred - y_centered) ** 2) + \\\n",
    "                             0.5 * self.lambda_reg * self.alpha.dot(K.dot(self.alpha))\n",
    "                \n",
    "                if abs(prev_loss - current_loss) < self.tol:\n",
    "                    break\n",
    "                    \n",
    "                prev_loss = current_loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        K_test = self.compute_kernel(X, self.X_train)\n",
    "        return K_test.dot(self.alpha) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (analytic): 0.010313441371516744\n",
      "MSE (gradient): 0.03719780263184441\n",
      "MSE (analytic_linear): 0.24677823920864825\n",
      "MSE (gradient_linear): 0.3986960462092339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(42)\n",
    "    \n",
    "n_samples = 3000\n",
    "X = np.random.randn(n_samples, 2)\n",
    "true_func = lambda x: np.sin(x[:, 0]) + np.cos(x[:, 1])\n",
    "y = true_func(X) + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model_analytic = KernelRidgeRegression(kernel='rbf', use_analytic=True, lambda_reg=0.1, gamma=1.0)\n",
    "model_gradient = KernelRidgeRegression(kernel='rbf', use_analytic=False, lambda_reg=0.1, gamma=1.0, \n",
    "                                          learning_rate=0.01, max_iter=1000)\n",
    "model_analytic_linear = KernelRidgeRegression(kernel='linear', use_analytic=True, lambda_reg=0.1, gamma=1.0)\n",
    "model_gradient_linear = KernelRidgeRegression(kernel='linear', use_analytic=False, lambda_reg=0.1, gamma=1.0, \n",
    "                                          learning_rate=0.01, max_iter=1000)\n",
    "\n",
    "model_analytic.fit(X_train, y_train)\n",
    "model_gradient.fit(X_train, y_train)\n",
    "model_analytic_linear.fit(X_train, y_train)\n",
    "model_gradient_linear.fit(X_train, y_train)\n",
    "\n",
    "pred_analytic = model_analytic.predict(X_test)\n",
    "pred_gradient = model_gradient.predict(X_test)\n",
    "pred_analytic_linear = model_analytic_linear.predict(X_test)\n",
    "pred_gradient_linear = model_gradient_linear.predict(X_test)\n",
    "\n",
    "print(\"MSE (analytic):\", mean_squared_error(y_test, pred_analytic))\n",
    "print(\"MSE (gradient):\", mean_squared_error(y_test, pred_gradient))\n",
    "print(\"MSE (analytic_linear):\", mean_squared_error(y_test, pred_analytic_linear))\n",
    "print(\"MSE (gradient_linear):\", mean_squared_error(y_test, pred_gradient_linear))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
